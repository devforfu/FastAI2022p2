{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f58a4b-970a-4143-9fd6-c2ef38d4990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1866a-2d85-4c9c-9a6e-5a74b768ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63513fd-6188-4bd6-bf94-5ea92fc07a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Callable\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "\n",
    "from tensorviewer import tv, opts\n",
    "from tensorviewer.config import set_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc9e976-82af-4741-950f-e61fce844012",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.disable(logging.WARNING)\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams[\"image.cmap\"] = \"gray_r\"\n",
    "set_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f73217-f966-4eaa-b783-df09b23e5ae1",
   "metadata": {},
   "source": [
    "## Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dac2ee-0967-4d63-baf3-23f70f266c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"fashion_mnist\"\n",
    "builder = load_dataset_builder(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b635571-0ab7-4b29-8b5e-1a4f448a19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(builder.info.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89039a9e-e973-4923-ae5f-6a5f202aeff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = load_dataset(name, ignore_verifications=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc09ca73-bf85-49b9-9ee4-958b5b57b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9114b3d-82a6-4ec4-92e8-30a1597aca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_KEY, Y_KEY = list(fashion[\"train\"].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae96e74-8f4b-444c-9fbd-0ce1ce5ac2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inplace(func: Callable) -> Callable:\n",
    "    def _inner(obj: Any) -> Any:\n",
    "        func(obj)\n",
    "        return obj\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eceb7a-93c3-4f3e-b54e-00c6beb95165",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplace\n",
    "def transform(batch: dict): batch[X_KEY] = [TF.to_tensor(t) for t in batch[X_KEY]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f522dd-9d8c-498b-800d-64f0c7ad76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1dba3d-e9dc-4e59-95cc-854df83f4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = fashion.with_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8a0f8-bb87-4863-a4b6-c72054bec96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv(torch.stack(tds[\"train\"][:10][\"image\"]).squeeze(), axes_visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003cb646-266a-4068-92af-610aa70a2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f76ad-7994-495f-8446-eaff20c79e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(DataLoader(tds[\"train\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7ccfd-7c79-4677-a39d-01a54a519a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Mapping\n",
    "from torch.utils.data import default_collate\n",
    "\n",
    "DEFAULT_DEVICE = \"cuda:1\"\n",
    "\n",
    "LABELS = fashion[\"train\"].features[\"label\"].names\n",
    "\n",
    "\n",
    "class CollateDict:\n",
    "    def __init__(self, keys: list[str], device: str = \"cpu\"):\n",
    "        self.fn = collate_dict(keys)\n",
    "        self.device = device\n",
    "    def __call__(self, batch: list[dict]):\n",
    "        return to_device(self.fn(batch), self.device)\n",
    "\n",
    "def collate_dict(keys: list[str]):\n",
    "    get = itemgetter(*keys)\n",
    "    def _collate(batch: list[dict]):\n",
    "        return tuple(default_collate(t) for t in zip(*[get(d) for d in batch]))\n",
    "    return _collate\n",
    "\n",
    "def to_device(x, device: str):\n",
    "    if isinstance(x, Mapping): return {k: v.to(device) for k, v in x.items()}\n",
    "    return type(x)(o.to(device) for o in x)\n",
    "\n",
    "def get_dls(datasets: dict, batch_size: int, **kwargs):\n",
    "    return {\n",
    "        key: DataLoader(dataset, batch_size, **kwargs) \n",
    "        for key, dataset in datasets.items()\n",
    "    }\n",
    "\n",
    "def get_labels(y): return itemgetter(*y)(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9161a54-1261-4107-8a96-55cf24349e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(tds, 16, collate_fn=CollateDict([\"image\", \"label\"], DEFAULT_DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587ea69-1c3c-45e0-b340-f22c9a1eeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dls[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847339a0-7d0c-4675-9d9f-a3964bf48ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({\"figure.figsize\": (7, 7), \"figure.dpi\": 70}):\n",
    "    tv(x.cpu().squeeze(), axes_titles=get_labels(y), axes_visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96593e98-996f-4d8b-a6e9-deb824c48277",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527be18c-b943-4641-a74e-4d70336331fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_edge = torch.tensor([\n",
    "    [-1., 1., 0.],\n",
    "    [-1., 1., 0.],\n",
    "    [-1., 1., 0.],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4379b5b-0db3-414f-87f8-acfeeb0e3b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = left_edge.view(-1) @ F.unfold(img, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdac712-b7a5-47bc-8acb-1294ccb2e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv(result.view(26, 26))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a95963-3d94-4902-a8f7-85f1e93ad625",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390403c-dc2c-4d51-8411-3a688f467c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni: int, nf: int, ks: int = 3, stride: int = 2, relu: bool = True):\n",
    "    m = nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2)\n",
    "    if relu: m = nn.Sequential(m, nn.ReLU())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373e7f9-5b6d-4a64-831c-3ffded24873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    conv(1, 4),\n",
    "    conv(4, 8),\n",
    "    conv(8, 16),\n",
    "    conv(16, 16),\n",
    "    conv(16, 10, relu=False),\n",
    "    nn.Flatten()\n",
    ").to(DEFAULT_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b998941-90cd-4d78-9afb-00b1dbe93f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from FastAI2022p2.core import fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabca82f-05ca-4a3f-91fc-d264afe4638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "lr = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751795f6-ad97-4896-bac2-68789e8d0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(tds, bs, collate_fn=CollateDict([\"image\", \"label\"], device=DEFAULT_DEVICE), num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360606c8-975e-4733-96b2-6739b68ac296",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(5, net, F.cross_entropy, optim.SGD(net.parameters(), lr=lr), dls[\"train\"], dls[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b799728-b9c8-4d70-aba6-a621aed9ff6d",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c30ef-90dd-4fdc-9633-f4cd32eca7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(ni: int, nf: int, ks: int = 3, relu: bool = True):\n",
    "    layers = [nn.UpsamplingNearest2d(scale_factor=2),\n",
    "              nn.Conv2d(ni, nf, stride=1, kernel_size=ks, padding=ks//2)]\n",
    "    if relu: layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811623b8-af50-4409-8ed1-57b6788e1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loss_fn, data_loader, epoch=0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total, count = 0.0, 0\n",
    "        for xb, _ in data_loader:\n",
    "            pred = model(xb)\n",
    "            n = len(xb)\n",
    "            count += n\n",
    "            total += loss_fn(pred, xb).item()*n\n",
    "    print(epoch, f\"{total/count:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b331b-89ba-4b67-a9c4-73899463fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb,_ in train_dl:\n",
    "            loss = loss_func(model(xb), xb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        validate(model, loss_func, valid_dl, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7e7d6-466c-41d3-82e1-40697a8f1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder = nn.Sequential(\n",
    "    nn.ZeroPad2d(2),\n",
    "    conv(1, 2),\n",
    "    conv(2, 4),\n",
    "    deconv(4, 2),\n",
    "    deconv(2, 1, relu=False),\n",
    "    nn.ZeroPad2d(-2),\n",
    "    nn.Sigmoid()\n",
    ").to(DEFAULT_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf63fb7-b22d-4454-9ad8-34493f22b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(auto_encoder, F.mse_loss, dls[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f26e148-59ee-4ab1-9e0d-05346b88577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(auto_encoder.parameters(), lr=0.01)\n",
    "fit(5, auto_encoder, F.mse_loss, opt, dls[\"train\"], dls[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a900d-01d9-4cdb-be36-2a70f9210425",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, _ = next(iter(dls[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ee9f3-7183-4302-b65a-e3eef5754c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = auto_encoder(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bad17-303b-49d9-a811-0b4eab7f8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv(pred.squeeze(), axes_visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0195e4-1126-4547-af2b-93f5190ff364",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv(xb.squeeze(), axes_visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7179df4d-c0c5-4ec0-a819-a6bcd43f0b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(auto_encoder.parameters(), lr=0.1)\n",
    "fit(5, auto_encoder, F.mse_loss, opt, dls[\"train\"], dls[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b7c95-b6e2-4e8c-932a-0db0913b62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv(auto_encoder(xb).squeeze(), axes_visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0edd931-d24e-4a08-8306-0705c42eae10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
